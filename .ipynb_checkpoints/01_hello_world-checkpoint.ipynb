{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "111438ce-4346-4b3e-be10-c875e9f27882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b85da-e1ab-46a7-91ed-d3db6e3005c2",
   "metadata": {},
   "source": [
    "## Connecting to Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60e4bcfb-fdb4-48b2-a016-a91134fc49d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.5.2\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Hello World\") \\\n",
    "    .master(\"spark://localhost:7077\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\") # Removign Warning\n",
    "\n",
    "\n",
    "print(\"Spark Version:\", spark.version)\n",
    "# spark_test.stop() # Encerrar a instância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23518b18-c373-44c2-9da0-bd20e113d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39215995-1609-43b3-ae42-94958c786df4",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "Nosso `script python` precisa usar a **API** do spark chamada `pyspark` para se conectar ao **Cluster do Spark**, que é onde irá acontecer toda a transformação dos dados de maneira rápida.\n",
    "\n",
    "Ou seja, para que as análises de dados sejam feitas de maneira mais rápida usando o spark, precisamos utilizar as funções ou métodos do Pyspark, que irá enviar as mensagens para os WORKERS do Spark. Contudo, as vezes temos pipelines que são muito específicos, então devemos transformar em funções python a trasnformação que queremos realizar, e aplicar o **apply** da instância do pyspark para que os dados sejam processados mais rápido no microservidor que está o Apache Spark."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
